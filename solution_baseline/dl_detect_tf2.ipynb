{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "dl_detect_tf2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# Lời giải cơ bản cho cuộc thi\n",
        "\n",
        "Đây là hướng dẫn một phương pháp cơ bản dùng để phát hiện hướng di chuyển (MOI) của phương tiện giao thông trong vùng trong vùng quan sát (ROI) cùng thời điểm phương tiện rời khỏi ROI.\n",
        "\n",
        "Hướng dẫn này sử dụng các mã nguồn mở từ các nguồn sau:\n",
        "\n",
        "* [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)\n",
        "\n",
        "* [Simple online and realtime tracking](https://github.com/abewley/sort)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Tổng quan phương pháp cơ bản được trình bày như sau:\n",
        "* **Phát hiện phương tiện giao thông trong từng frame của video**: Sử dụng TensorFlow Object Detection API. Kết quả trả về là một danh sách các bounding box ứng với tất cả các phương tiện giao thông trong ảnh.\n",
        "* **Theo vết (multiple objects tracking)**: Dựa vào IOU (chỉ số đo đạc mức độ trùng lắp của hai bounding box), các bounding box ở các frame liên tiếp sẽ được gom nhóm và từ đó sẽ hình thành quỹ đạo di chuyển của chính phương tiện đó.\n",
        "* **Xác định hướng di chuyển (MOI) dựa trên quỹ đạo**: MOI của phương tiện sẽ được lựa chọn dựa trên độ tương đồng (ở đây sử dụng Cosine Similarity Score) giữa quỹ đạo của mỗi phương tiện và các MOI sẽ được tính toán.   \n",
        "\n",
        "**Lưu ý**: Trong lời giải cơ bản này, chỉ minh họa việc phát hiện và đếm phương tiện xe máy. Bạn cần chỉnh sửa và cải tiến để có thể đếm được tất cả phương tiện giao thông mà đề bài yêu cầu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LBZ9VWZZFUCT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "551fc28e-4957-4d37-9ef8-63693d679ed5"
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.2.0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4YF0EnPMVFA",
        "colab_type": "text"
      },
      "source": [
        "# Cấu hình thư mục lưu trữ dữ liệu\n",
        "\n",
        "Hướng dẫn này được chạy trên [Google Colab](https://colab.research.google.com/) (xem phần [Colab FAQ](https://research.google.com/colaboratory/faq.html) để biết thêm thông tin cần lưu ý)\n",
        "\n",
        "Đoạn chương trình sau cấu hình đường dẫn thư mục Google Drive của bạn để thuận tiện cho việc chạy thí nghiệm nhiều lần và lưu trữ dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hynjRVJp4rC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "503875af-c93e-492f-b2a7-c1e3a3c48326"
      },
      "source": [
        "\n",
        "# Mount \"My Drive\" into /content/drive\n",
        "from google.colab import drive\n",
        "\n",
        "google_drive_dir = 'Shared/HCMCAIC'  # @param\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "mount_point = '/content/drive/My Drive/{}'.format(google_drive_dir)\n",
        "\n",
        "# Change the root directory to your mount_point\n",
        "% cd '$mount_point'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogDEF-0I_mCv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oi28cqGGFWnY",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the baseline repository \n",
        "if not pathlib.Path('ai-challenge-baseline').exists():\n",
        "  ! git clone https://github.com/hcmcaic/ai-challenge-baseline\n",
        "\n",
        "# \n",
        "% cd ai-challenge-baseline\n",
        "\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NwdsBdGhFanc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6747ce0e-9027-456f-982b-8e912830984b"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5aLuBmiZqyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "2246d062-46a0-4a63-9cff-988e805998d9"
      },
      "source": [
        "# Install the requirements package for SORT source code\n",
        "! pip install filterpy scikit-image lap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LT09Kh83xRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gkBIEc_Ri1I",
        "colab_type": "text"
      },
      "source": [
        "# Đọc dữ liệu từ video\n",
        "\n",
        "Đoạn chương trình dưới đây dùng để trích xuất tất cả các khung ảnh (frame) của video và lưu lại dưới dạng các ảnh riêng lẻ trong thư mục tạm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgYcoc4sBEx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import argparse\n",
        "from tqdm import tqd#@markdown Your videos is stored in: \n",
        "\n",
        "input_dir = 'sample_data/videos' # @param\n",
        "\n",
        "#@markdown  Frames extracted from videos will be stored in:\n",
        "output_dir = 'sample_data/frames'  # @params'  \n",
        "\n",
        "\n",
        "video_paths = []\n",
        "for r, d, f in os.walk(input_dir):\n",
        "    for file in f:\n",
        "        if '.mp4' in file:\n",
        "            video_paths.append(os.path.join(r, file))\n",
        "\n",
        "\n",
        "for video_path in video_paths:\n",
        "    print(video_path)\n",
        "\n",
        "\n",
        "\n",
        "for video_path in video_paths:\n",
        "    video_dir_path = os.path.join(output_dir, os.path.splitext(os.path.basename(video_path))[0])\n",
        "    if not os.path.isdir(video_dir_path):\n",
        "        os.makedirs(video_dir_path)\n",
        "\n",
        "    vid_cap = cv2.VideoCapture(video_path)\n",
        "    num_frms, original_fps = int(vid_cap.get(cv2.CAP_PROP_FRAME_COUNT)), vid_cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "## Number of skip frames\n",
        "    time_stride = 1\n",
        "\n",
        "    for frm_id in tqdm(range(0, num_frms, time_stride)):\n",
        "        vid_cap.set(cv2.CAP_PROP_POS_FRAMES, frm_id)\n",
        "        _, im = vid_cap.read()\n",
        "\n",
        "        cv2.imwrite(os.path.join(video_dir_path, str(frm_id) + '.jpg'), im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY4a6D4I3xRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def get_keypoint_tuples(eval_config):\n",
        "  \"\"\"Return a tuple list of keypoint edges from the eval config.\n",
        "  \n",
        "  Args:\n",
        "    eval_config: an eval config containing the keypoint edges\n",
        "  \n",
        "  Returns:\n",
        "    a list of edge tuples, each in the format (start, end)\n",
        "  \"\"\"\n",
        "  tuple_list = []\n",
        "  kp_list = eval_config.keypoint_edge\n",
        "  for edge in kp_list:\n",
        "    tuple_list.append((edge.start, edge.end))\n",
        "  return tuple_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrTxugQ23xRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_zoo_list(model_zoo_file):\n",
        "    \"\"\"Return a dictionary of model with config and pretrained weight.\n",
        "\n",
        "    Args:\n",
        "      eval_config: an eval config containing the keypoint edges\n",
        "\n",
        "    Returns:\n",
        "      a dict of tuples, each in the format model_name:(config_file, pretrained_weight_link)\n",
        "    \"\"\"\n",
        "    model_zoo_dict = dict()\n",
        "    with open(model_zoo_file) as csvfile:\n",
        "        model_reader = csv.reader(csvfile, delimiter=',')\n",
        "        for row in model_reader:\n",
        "            model_zoo_dict[row[0]] = (row[1], row[2])\n",
        "    \n",
        "    return model_zoo_dict\n",
        "            \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BqBoTTu3xRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1e5622b-a42e-4941-ecbb-c778b2cc32bb"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLSqXV_U3xR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def get_keypoint_tuples(eval_config):\n",
        "  \"\"\"Return a tuple list of keypoint edges from the eval config.\n",
        "  \n",
        "  Args:\n",
        "    eval_config: an eval config containing the keypoint edges\n",
        "  \n",
        "  Returns:\n",
        "    a list of edge tuples, each in the format (start, end)\n",
        "  \"\"\"\n",
        "  tuple_list = []\n",
        "  kp_list = eval_config.keypoint_edge\n",
        "  for edge in kp_list:\n",
        "    tuple_list.append((edge.start, edge.end))\n",
        "  return tuple_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZCF5UoQJJbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGqOfyODJKxn",
        "colab_type": "text"
      },
      "source": [
        "# Chuẩn bị model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKzgcA_2JkuB",
        "colab_type": "text"
      },
      "source": [
        "Đoạn chương trình sau sử dụng Detection API có sẵn, bạn có thể lựa chọn hoặc thay đổi các detection architecture cùng với backbone mà model zoo cung cấp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49wKV7ExjcUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_zoo_dict = get_model_zoo_list('solution_baseline/model_zoo.txt')\n",
        "model_name = 'CenterNet HourGlass104 512x512'\n",
        "model_config_file, model_weight_file = model_zoo_dict[model_name]\n",
        "model_weight_link = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + model_weight_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv1KH_opJ4pU",
        "colab_type": "text"
      },
      "source": [
        "Tải và giải nén pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc0mP-E83xR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "6c0a7aa8-5922-4293-9d2a-54fbb6010fb1"
      },
      "source": [
        "!wget $model_weight_link\n",
        "!tar -xf $model_weight_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBvqoYio3xSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline_config = os.path.join('models/research/object_detection/configs/tf2/', model_config_file)\n",
        "model_dir = model_weight_file[:-7] + '/checkpoint'\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfH54nZw3xSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map_path = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLoAfCIZ3xSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dir = output_dir + '/sample_01'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xJ-g4FSUx1l",
        "colab_type": "text"
      },
      "source": [
        "# Lấy thông tin MOI và ROI từ json\n",
        "Đọc file json ứng với mỗi video chứa thông tin ROI và MOI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ile9zBpn3xSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "def load_zone_anno(json_filename):\n",
        "  \"\"\"\n",
        "  Load the json with ROI and MOI annotation.\n",
        "\n",
        "  \"\"\"\n",
        "  with open(json_filename) as jsonfile:\n",
        "    dd = json.load(jsonfile)\n",
        "    polygon = [(int(x), int(y)) for x, y in dd['shapes'][0]['points']]\n",
        "    paths = {}\n",
        "    for it in dd['shapes'][1:]:\n",
        "      kk = str(int(it['label'][-2:]))\n",
        "      paths[kk] = [(int(x), int(y)) for x, y\n",
        "              in it['points']]\n",
        "  return polygon, paths\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uttgiFRY3xSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "polygon, paths = load_zone_anno('sample_data/videos/sample_01.json')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hc3s7VfUAhl",
        "colab_type": "text"
      },
      "source": [
        "# Phát hiện hướng duy chuyển của các xe máy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0tEGNvVP3Ab",
        "colab_type": "text"
      },
      "source": [
        "Trong hướng dẫn này chỉ đếm một loại phương tiện là xe máy. Đối với source code hiện tại, mỗi loại phương tiện cần tạo một tracker khác nhau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciSftBRfUrsj",
        "colab_type": "text"
      },
      "source": [
        "Hàm kiểm tra phương tiện phát hiện được có nằm trong ROI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6DEp8DV3xSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from solution_baseline import bb_polygon\n",
        "def check_bbox_intersect_polygon(polygon, bbox):\n",
        "  \"\"\"\n",
        "  \n",
        "  Args:\n",
        "    polygon: List of points (x,y)\n",
        "    bbox: A tuple (xmin, ymin, xmax, ymax)\n",
        "  \n",
        "  Returns:\n",
        "    True if the bbox intersect the polygon\n",
        "  \"\"\"\n",
        "  x1, y1, x2, y2 = bbox\n",
        "  bb = [(x1,y1), (x2, y1), (x2,y2), (x1,y2)]\n",
        "  return bb_polygon.is_bounding_box_intersect(bb, polygon)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2uKQUur3xSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from solution_baseline.sort import *\n",
        "moto_tracker = Sort()\n",
        "truck_tracker = Sort()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuWlt2S03xSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an motobikes tracker with default parameter.\n",
        "# Please read the sort documentation for the custom paramenters.\n",
        "\n",
        "moto_tracker = Sort()\n",
        "\n",
        "# If you want to track another vehicle class, you need to declare a new tracker.\n",
        "# truck_tracker = Sort()\n",
        "\n",
        "track_dict = {}\n",
        "\n",
        "N_FRAMES = 20\n",
        "\n",
        "for frame_id in range(1, N_FRAMES):\n",
        "  image_path = os.path.join(image_dir, '{}.jpg'.format(frame_id))\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "\n",
        "  im_width, im_height, _ = image_np.shape\n",
        "  input_tensor = tf.convert_to_tensor(\n",
        "      np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "  detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "\n",
        "  boxes = detections['detection_boxes'][0]\n",
        "  scores = detections['detection_scores'][0]\n",
        "  classes = detections['detection_classes'][0]\n",
        "\n",
        "\n",
        "  dets = []\n",
        "  for bb, s, c in zip(boxes, scores, classes):\n",
        "    ymin, xmin, ymax, xmax = bb.numpy()\n",
        "    xmin, ymin, xmax, ymax = xmin*im_width, ymin*im_height, xmax*im_width, ymax*im_height\n",
        "    if check_bbox_intersect_polygon(polygon, (xmin, ymin, xmax, ymax)):\n",
        "      # check if the bbox is in ROI\n",
        "      dets.append((frame_id, c.numpy(), xmin, ymin, xmax, ymax, s.numpy()))\n",
        "\n",
        "\n",
        "  label_id_offset = 1\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "\n",
        "  dets = np.array(dets)\n",
        "\n",
        "  # Only get the detections with the class label is '3' which indicate the motobike class.\n",
        "  moto_dets = dets[dets[:,1]==3]\n",
        "  moto_dets = np.array(moto_dets)\n",
        "\n",
        "  trackers = moto_tracker.update(moto_dets)\n",
        "  for xmin, ymin, xmax, ymax, track_id in trackers:\n",
        "    track_id = int(track_id)\n",
        "    # print(track_id)\n",
        "    if track_id not in track_dict.keys():\n",
        "      track_dict[track_id] = [(xmin, ymin, xmax, ymax, frame_id)]\n",
        "    else:\n",
        "      track_dict[track_id].append((xmin, ymin, xmax, ymax, frame_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJibvnHA3xSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# moto_vector_list: list of tuples (first_point, last_point, last_frame_id)\n",
        "# list of moto movement vector and the last frame_id when it is still in the ROI.\n",
        "\n",
        "moto_vector_list = []\n",
        "for tracker_id, tracker_list in track_dict.items():\n",
        "  if len(tracker_list) > 1:\n",
        "    first = tracker_list[0]\n",
        "    last = tracker_list[-1]\n",
        "    first_point = ((first[2] - first[0])/2, (first[3] - first[1])/2)\n",
        "    last_point = ((last[2] - last[0])/2, (last[3] - last[1])/2)\n",
        "    moto_vector_list.append((first_point, last_point, last[4]))\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Foy99tKg3xSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosin_similarity(a2d, b2d):\n",
        "  \n",
        "  a = np.array((a2d[1][0] - a2d[0][0], a2d[1][1 ]- a2d[0][1]))\n",
        "  b = np.array((b2d[1][0] - b2d[0][1], b2d[1][1] - b2d[1][0]))\n",
        "  return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c576pYuNaQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MOTO_CLASS_ID = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCjVR7a9TxaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Đếm số lương\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLkDtcLPT4Uk",
        "colab_type": "text"
      },
      "source": [
        "Phát hiện MOI tương ứng với mỗi xe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-Q9yaFbq3xSv"
      },
      "outputs": [],
      "source": [
        "def counting_moi(paths, moto_vector_list):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    paths: List of MOI - (first_point, last_point)\n",
        "    moto_vector_list: List of tuples (first_point, last_point, last_frame_id) \n",
        "  \n",
        "  Returns:\n",
        "    A list of tuples (frame_id, movement_id, vehicle_class_id)\n",
        "  \"\"\"\n",
        "  moi_detection_list = []\n",
        "  for moto_vector in moto_vector_list:\n",
        "    max_cosin = -2\n",
        "    movement_id = ''\n",
        "    last_frame = 0\n",
        "    for movement_label, movement_vector in paths.items():\n",
        "      cosin = cosin_similarity(movement_vector, moto_vector)\n",
        "      if cosin > max_cosin:\n",
        "        max_cosin = cosin\n",
        "        movement_id = movement_label\n",
        "        last_frame = moto_vector[2]\n",
        "\n",
        "    moi_detection_list.append((last_frame, movement_id, MOTO_CLASS_ID))\n",
        "  return moi_detection_list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uPXjMdpJFDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moto_moi_detections = counting_moi(paths, moto_vector_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xsPexKFEssj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a5dbdb6-82ae-4ffb-be8d-90e679206825"
      },
      "source": [
        "print(moto_moi_detections)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Xuất kết quả theo định dạng nộp\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS16AQoA3xS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "result_filename = 'result.txt'\n",
        "video_id = '000'\n",
        "with open(result_filename, 'w') as result_file:\n",
        "  for frame_id, movement_id, vehicle_class_id in moto_moi_detections:\n",
        "    result_file.write('{} {} {} {}\\n'.format(video_id, frame_id, movement_id, vehicle_class_id))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}